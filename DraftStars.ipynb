{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Draft Stars - Model<h1>\n",
        "\n",
        "<h3>Creates, trains and exports a model which predicts the outcome of Brawl Stars matches.</h3>\n",
        "<h4>Created with PyTorch</h4>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<h3>Input</h3>\n",
        "\n",
        "To run this program, you need a dataset of Brawl Stars matches. You can collect one yourself with another repo of mine: <a href=\"https://github.com/mcmckinley/DraftStarsDataCollection\">DraftStarsDataCollection</a>\n",
        "\n",
        "<br>\n",
        "\n",
        "Each match in the dataset contains the following values:\n",
        "* IDs for all six brawlers<sub>1</sub>\n",
        "  * There are six players in each match (3 versus 3). The first three IDs for each match refer to the left (or blue) team. The last three refer to the right (or red) team.\n",
        "  * Very important note: there are no brawlers with indices 33 and 55. This is because the official brawler list, when requested from Supercell's API, does not include brawlers at these indices.\n",
        "* Which team won\n",
        "  * This column is titled 'did_blue_team_win'. 1 means yes and a 0 means no (the team on right, or red team, won.)\n",
        "* Trophy counts of each player on that brawler\n",
        "  * This is useful for weighing the statistical significance of any given match. When a low skill team wins, we assume that their team composition was superior.\n",
        "\n",
        "<br>\n",
        "\n",
        "I would strongly recommmend initializing the brawler and map embedding layers with manually chosen values. With Google Colab this notebook is already set up  to import spreadsheets of initialization values that I have created myself. If you wish to run these locally, you should download my spreadsheets or make your own (would not recommend, it takes a while.)\n",
        "\n",
        "\n",
        "<p>Brawler Data Spreadsheet:\n",
        "\n",
        "* <a href=\"https://docs.google.com/spreadsheets/d/17hqBX-6XEA4nGCOcQizNGTZt8ZNelkg0OEtDC4DR1hE/edit?gid=0#gid=0\">View</a>\n",
        "\n",
        "* <a href=\"https://docs.google.com/spreadsheets/d/e/  2PACX-1vRZXNyNjU1csRxyikhZ-GbnLrt-99bX0FCvxnBKzobXtXpWmvJl8gtNfb46CDIZ50LLHWoY9JU-U4A2/pub?output=csv\">Download as CSV</a>\n",
        "</p>\n",
        "\n",
        "<p>Map Data Spreadsheet:\n",
        "\n",
        "* <a href=\"https://docs.google.com/spreadsheets/d/1eU8GuR_vp8UZdf4gPxDEHrkjTeGk_PDUlVAdkedardA/edit?usp=sharing\">View</a>\n",
        "\n",
        "* <a href=\"https://docs.google.com/spreadsheets/d/e/ 1eU8GuR_vp8UZdf4gPxDEHrkjTeGk_PDUlVAdkedardA/pub?output=csv\">Download as CSV</a>\n",
        "\n",
        "\n",
        "---\n",
        "<h3>Output</h3>\n",
        "\n",
        "* The pytorch model\n",
        "* Embedding layers for the brawlers and maps, in CSV format\n",
        "  * Why CSV? For one, it's readable. It's interesting to see how the model takes the initialization data and tweaks it. More importantly however is the fact that we can alter it ourselves.\n",
        "* A list of maps, in the order than the model interprets them. Without this the backend won't know which map is selected.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fs4xp8S53dtk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4ecmFVVhzU5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SECTION 1</h1>\n",
        "<h2>Data - Import, balance, weigh, split</h2>"
      ],
      "metadata": {
        "id": "ww00XqiKC0-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIebMfkcyg9m"
      },
      "outputs": [],
      "source": [
        "# 1.0 Import data\n",
        "\n",
        "url = 'https://drive.google.com/uc?export=download&id=14oFQeB8Dmv-5nBZKwAVax7qcegRfRz6n' # 750k battles, September 10th\n",
        "\n",
        "raw_df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Remove battles containing players with too high/low of a skill level. These are hard to interpret.\n",
        "\n",
        "df = raw_df.copy()\n",
        "\n",
        "print('Total battles:', len(df))\n",
        "\n",
        "max_trophies = 1000\n",
        "\n",
        "columns_to_check = ['a1_t', 'a2_t', 'a3_t', 'b1_t', 'b2_t', 'b3_t']\n",
        "\n",
        "# Apply the threshold condition to all specified columns\n",
        "df = df.loc[(raw_df[columns_to_check] < max_trophies).all(axis=1)]\n",
        "\n",
        "print(\"Removed battles above\", max_trophies, ':', len(df))\n",
        "\n",
        "min_trophies = 500\n",
        "\n",
        "df = df.loc[(raw_df[columns_to_check] > min_trophies).all(axis=1)]\n",
        "\n",
        "print(\"Removed battles below\", min_trophies, ':', len(df))"
      ],
      "metadata": {
        "id": "CUbxtntVvzbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011ec405-b9c4-486f-c332-59cf9eea34d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total battles: 723763\n",
            "Removed battles above 1000 : 562431\n",
            "Removed battles below 500 : 479776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These maps contain bad data\n",
        "df = df[df['map'] != 'Rusty Rebound']\n",
        "df = df[df['map'] != 'Spring Back Alley']\n",
        "df = df[df['map'] != 'Touch Up Tavern']\n",
        "df = df[df['map'] != 'Greasepaint Grass']\n",
        "df = df[df['map'] != 'Dye Direct']\n",
        "df = df[df['map'] != 'Chromatic Cress']\n",
        "df = df[df['map'] != 'Spots Of Yore']\n",
        "df = df[df['map'] != 'Tint Terrace']\n",
        "#df = df[df['map'] != 'Shooting Star']\n",
        "#df = df[df['map'] != 'Layer Cake']\n",
        "#df = df[df['map'] != 'Hideout']\n",
        "#df = df[df['map'] != 'Temple Ruins']\n",
        "#df = df[df['map'] != 'Split']\n",
        "#df = df[df['map'] != 'Canal Grande']\n",
        "#df = df[df['map'] != 'Galaxy Arena']\n",
        "#df = df[df['map'] != 'Excel']\n",
        "#df = df[df['map'] != 'Outlaw Camp']\n",
        "#df = df[df['map'] != 'Triple Dribble']\n",
        "#df = df[df['map'] != 'Bandit Stash']\n",
        "#df = df[df['map'] != 'Pit Stop']\n",
        "#df = df[df['map'] != 'Bridge Too Far']\n",
        "#df = df[df['map'] != 'Crystal Arcade']\n",
        "df = df[df['map'] != 'Rock Bottom']\n",
        "df = df[df['map'] != 'Burger Bay']\n",
        "df = df[df['map'] != 'Flying Fish-sticks']\n",
        "df = df[df['map'] != 'Sunken Treasure']\n",
        "df = df[df['map'] != 'Close Call']\n",
        "df = df[df['map'] != 'Hairy Horrors']\n",
        "\n",
        "\n",
        "\n",
        "print(\"Length without these maps:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxaTGZRsNIMm",
        "outputId": "2c5d129d-228a-42c6-9671-934354a1035a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length without these maps: 451523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aJrpE9nWwVi",
        "outputId": "dfc639bf-564c-4a5d-9dda-6973d7d90557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of times blue won: 221487\n",
            "Number of times red won: 230036\n",
            "Will flip 4275 rows\n",
            "Data has been balanced.\n",
            "Number of times blue won: 225762\n",
            "Number of times red won: 225761\n"
          ]
        }
      ],
      "source": [
        "# 1.2 - Balance data\n",
        "\n",
        "# It is crucial that our data has an equal number of victories / defeats on either side,\n",
        "# so that the model doesn't learn to prefer one side over the other.\n",
        "# To solve this, we flip some of the matches so that the winner is on the other side.\n",
        "\n",
        "# Count the occurrences of 1s and 0s\n",
        "counts = df['did_blue_team_win'].value_counts()\n",
        "team_a_victories = counts.get(0, 0)\n",
        "team_b_victories = counts.get(1, 0)\n",
        "print(\"Number of times blue won:\", team_a_victories)\n",
        "print(\"Number of times red won:\", team_b_victories)\n",
        "\n",
        "num_rows_to_flip = (team_a_victories - team_b_victories) // 2\n",
        "\n",
        "overrepresented_bit = (1 if num_rows_to_flip < 0 else 0)\n",
        "\n",
        "num_rows_to_flip = abs(num_rows_to_flip)\n",
        "\n",
        "print('Will flip', num_rows_to_flip, 'rows')\n",
        "\n",
        "# Identify which rows should be candidates to be flipped\n",
        "rows_to_flip = df['did_blue_team_win'] == overrepresented_bit\n",
        "\n",
        "# Get the indices of the rows to flip\n",
        "indices_to_flip = df[rows_to_flip].index[:num_rows_to_flip]\n",
        "\n",
        "# Perform the flipping operations on the selected rows\n",
        "# Flip 'did_blue_team_win' values\n",
        "df.loc[indices_to_flip, 'did_blue_team_win'] = 1 - df.loc[indices_to_flip, 'did_blue_team_win']\n",
        "\n",
        "# Flip the brawler IDs and trophy counts\n",
        "for x in range(1, 4):\n",
        "    a_col = 'a' + str(x)\n",
        "    b_col = 'b' + str(x)\n",
        "    a_t_col = a_col + '_t'\n",
        "    b_t_col = b_col + '_t'\n",
        "\n",
        "    # Use temporary variable to swap the columns\n",
        "    temp = df.loc[indices_to_flip, a_col].copy()\n",
        "    df.loc[indices_to_flip, a_col] = df.loc[indices_to_flip, b_col]\n",
        "    df.loc[indices_to_flip, b_col] = temp\n",
        "\n",
        "    temp = df.loc[indices_to_flip, a_t_col].copy()\n",
        "    df.loc[indices_to_flip, a_t_col] = df.loc[indices_to_flip, b_t_col]\n",
        "    df.loc[indices_to_flip, b_t_col] = temp\n",
        "\n",
        "print('Data has been balanced.')\n",
        "\n",
        "counts = df['did_blue_team_win'].value_counts()\n",
        "team_a_victories = counts.get(0, 0)\n",
        "team_b_victories = counts.get(1, 0)\n",
        "print(\"Number of times blue won:\", team_a_victories)\n",
        "print(\"Number of times red won:\", team_b_victories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZNaZIk7i14f"
      },
      "outputs": [],
      "source": [
        "# 1.3 - Weigh each match based on skill:\n",
        "#       - If a high trophy team wins, this isn't too meaningful.\n",
        "#       - If a low trophy team wins, we assume it's because they have a superior team composition.\n",
        "#         Thus we tell the model to consider these matches more heavily.\n",
        "\n",
        "df['blue_team_highest_trophies'] = df[['a1_t', 'a2_t', 'a3_t']].max(axis=1)\n",
        "df['red_team_highest_trophies'] = df[['b1_t', 'b2_t', 'b3_t']].max(axis=1)\n",
        "\n",
        "df['blue_team_trophy_advantage'] = df['blue_team_highest_trophies'] - df['red_team_highest_trophies']\n",
        "\n",
        "# Calculate weight based on:\n",
        "#   - who has the trophy advantage\n",
        "#   - who won\n",
        "e = 2.71\n",
        "k = 0.01\n",
        "df['weight'] = (np.where(df['did_blue_team_win'] == 1,\n",
        "                         e**(-k * (df['blue_team_trophy_advantage'])),   # if team B wins (notice the -k)\n",
        "                         e**( k * (df['blue_team_trophy_advantage']))))  # if team A wins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93gwi7oqbiKA"
      },
      "outputs": [],
      "source": [
        "# 1.4 - Drop data that is no longer necessary\n",
        "\n",
        "columns_to_drop = ['a1_t', 'a2_t', 'a3_t', 'b1_t', 'b2_t', 'b3_t', 'blue_team_highest_trophies', 'red_team_highest_trophies', 'blue_team_trophy_advantage']\n",
        "df.drop(columns=columns_to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVIGuz7WcqbO",
        "outputId": "fcb15326-6f87-480e-d093-7724b2c6dcc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of brawlers: 86\n",
            "number of maps: 53\n",
            "[40  5 11  6 51 84 31  0]\n"
          ]
        }
      ],
      "source": [
        "# 1.5 - Convert the data into integer arrays\n",
        "\n",
        "brawlers = ['SHELLY', 'COLT', 'BULL', 'BROCK', 'RICO', 'SPIKE', 'BARLEY', 'JESSIE', 'NITA', 'DYNAMIKE', 'EL PRIMO', 'MORTIS', 'CROW', 'POCO', 'BO', 'PIPER', 'PAM', 'TARA', 'DARRYL', 'PENNY', 'FRANK', 'GENE', 'TICK', 'LEON', 'ROSA', 'CARL', 'BIBI', '8-BIT', 'SANDY', 'BEA', 'EMZ', 'MR. P', 'MAX', 'empty1', 'JACKY', 'GALE', 'NANI', 'SPROUT', 'SURGE', 'COLETTE', 'AMBER', 'LOU', 'BYRON', 'EDGAR', 'RUFFS', 'STU', 'BELLE', 'SQUEAK', 'GROM', 'BUZZ', 'GRIFF', 'ASH', 'MEG', 'LOLA', 'FANG', 'empty2', 'EVE', 'JANET', 'BONNIE', 'OTIS', 'SAM', 'GUS', 'BUSTER', 'CHESTER', 'GRAY', 'MANDY', 'R-T', 'WILLOW', 'MAISIE', 'HANK', 'CORDELIUS', 'DOUG', 'PEARL', 'CHUCK', 'CHARLIE', 'MICO', 'KIT', 'LARRY & LAWRIE', 'MELODIE', 'ANGELO', 'DRACO', 'LILY', 'BERRY', 'CLANCY', 'MOE', 'KENJI']\n",
        "maps = list(set(df['map'].values)) # Take the maps column and remove duplicates\n",
        "\n",
        "num_brawlers = len(brawlers)\n",
        "num_maps = len(maps)\n",
        "\n",
        "print(f'number of brawlers: {num_brawlers}')\n",
        "print(f'number of maps: {num_maps}')\n",
        "\n",
        "def brawler_index(brawler):\n",
        "    return brawlers.index(brawler)\n",
        "\n",
        "def map_index(map):\n",
        "    return maps.index(map)\n",
        "\n",
        "df['map_index'] = df['map'].apply(map_index)\n",
        "\n",
        "data_list = df[['a1', 'a2', 'a3', 'b1', 'b2', 'b3', 'map_index', 'did_blue_team_win']]\n",
        "data_list_weights = df['weight']\n",
        "data_list = data_list.to_numpy()\n",
        "\n",
        "print(data_list[0]) # to show that the data is being interpreted correctly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.7 - Convert dataset into train_test_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_data = df[['a1', 'a2', 'a3', 'b1', 'b2', 'b3', 'map_index']]\n",
        "target_data = df['did_blue_team_win']\n",
        "weight_data = df['weight']\n",
        "\n",
        "input_data = input_data.to_numpy()\n",
        "target_data = target_data.to_numpy()\n",
        "weight_data = weight_data.to_numpy()\n",
        "\n",
        "print(type(input_data))\n",
        "print(input_data.shape)\n",
        "\n",
        "train_input, test_input, train_target, test_target, train_weight, test_weight = train_test_split(input_data, target_data, weight_data, test_size=0.05, random_state=42)\n",
        "train_input = torch.tensor(train_input, dtype=torch.int)\n",
        "test_input = torch.tensor(test_input, dtype=torch.int)\n",
        "train_target = torch.tensor(train_target, dtype=torch.float)\n",
        "test_target = torch.tensor(test_target, dtype=torch.float)\n",
        "train_weight = torch.tensor(train_weight, dtype=torch.float)\n",
        "test_weight = torch.tensor(test_weight, dtype=torch.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fba_F3BgDOqM",
        "outputId": "d7923311-19c0-44e6-a692-cdbce4a83a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(451523, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.8 - Use loading system on dataset\n",
        "batch_size = 1024\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class WeightedDataset(Dataset):\n",
        "    def __init__(self, data, targets, weights):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.weights = weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.targets[idx], self.weights[idx]\n",
        "\n",
        "train_dataset = WeightedDataset(train_input, train_target, train_weight)\n",
        "test_dataset = WeightedDataset(test_input, test_target, test_weight)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "0YzB2Lgb_kAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SECTION 2</h1>\n",
        "<h2>Import manually predetermined weights for initialization</h2>"
      ],
      "metadata": {
        "id": "MevJ3h_DFml6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.0 - Initialize brawler weights with values that have been manually determined (by me)\n",
        "\n",
        "# This is one thing that differs my model from ChatGPT.\n",
        "# I have the luxury of manually initializing my values, based on real traits that each character has.\n",
        "\n",
        "brawler_data_spreadsheet = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRZXNyNjU1csRxyikhZ-GbnLrt-99bX0FCvxnBKzobXtXpWmvJl8gtNfb46CDIZ50LLHWoY9JU-U4A2/pub?output=csv'\n",
        "brawler_data_df = pd.read_csv(brawler_data_spreadsheet)\n",
        "\n",
        "# Drop these columns\n",
        "columns_to_drop = ['mico', 'chuck', 'mortis', 'sprout', 'bonnie', 'draco']\n",
        "for column in columns_to_drop:\n",
        "  brawler_data_df.drop(column, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "brawler_data_list = brawler_data_df.to_numpy()\n",
        "traits_per_brawler = len(brawler_data_list[0]) - 1 # minus 1 for the name column\n",
        "\n",
        "# First, set the brawler embeddings to 0\n",
        "initial_brawler_embedding = torch.zeros(num_brawlers, traits_per_brawler)\n",
        "\n",
        "# Then, update the embedding weights\n",
        "for brawler_data in brawler_data_list:\n",
        "  numeric_values = [float(val) for val in brawler_data[1:]]\n",
        "  initial_brawler_embedding[brawler_index(brawler_data[0])] = torch.tensor(numeric_values)\n",
        "\n",
        "# Add blank columns for the model to use freely\n",
        "num_extra_columns_to_add = 9\n",
        "print(f'using {num_extra_columns_to_add} blank columns')\n",
        "extra_columns = torch.zeros(num_brawlers, num_extra_columns_to_add)\n",
        "initial_brawler_embedding = torch.cat([initial_brawler_embedding, extra_columns], dim=1)\n",
        "\n",
        "initial_brawler_embedding = nn.Embedding.from_pretrained(initial_brawler_embedding, freeze=False)\n",
        "\n",
        "traits_per_brawler += num_extra_columns_to_add\n",
        "print('Traits per brawler:', traits_per_brawler)\n",
        "print(initial_brawler_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9MMK1MKwTOi",
        "outputId": "e1439919-7e9d-4247-e542-67426333b7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using 9 blank columns\n",
            "Traits per brawler: 44\n",
            "Embedding(86, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.0b - Initialize map weights with manually determined values\n",
        "\n",
        "url_of_map_data = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRnV3wZG4MMDm2mROwP8ejxaolBuYuV7BjygLlA2X6FLsLmYp3zplalDfveFTJPKZVpcCPWxCSJr4Y3/pub?output=csv'\n",
        "map_data_df = pd.read_csv(url_of_map_data)\n",
        "map_data_list = map_data_df.to_numpy()\n",
        "\n",
        "traits_per_map = len(map_data_list[0]) - 1 # minus 1 for the map's name\n",
        "\n",
        "# Initialize the map embeddings to 0\n",
        "initial_map_embedding = torch.zeros(num_maps, traits_per_map)\n",
        "\n",
        "# Set the map embedding weights\n",
        "for map_data in map_data_list:\n",
        "  print(f' FOUND {map_data}')\n",
        "  numeric_values = [float(val) for val in map_data[1:]]\n",
        "  try:\n",
        "    initial_map_embedding[map_index(map_data[0])] = torch.tensor(numeric_values)\n",
        "  except ValueError: # A given map might not necessarily occur in the dataset.\n",
        "    continue\n",
        "\n",
        "initial_map_embedding = nn.Embedding.from_pretrained(initial_map_embedding, freeze=False)\n",
        "\n",
        "print('Traits per map:', traits_per_map)\n",
        "print(initial_map_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZsXKL_nvxyt",
        "outputId": "28e9d925-3a3c-4c61-f553-6945fe7f37b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FOUND ['Infinite Doom' 7.0 10.0 9.0 1 0 0 0 0 10 0]\n",
            " FOUND ['Sneaky Fields' 1.0 10.0 10.0 4 0 0 10 0 0 0]\n",
            " FOUND ['Goldarm Gulch' 3.0 10.0 5.0 8 0 0 0 0 10 0]\n",
            " FOUND ['Flaring Phoenix' 3.0 3.0 7.0 8 0 0 0 0 10 0]\n",
            " FOUND ['Double Swoosh' 3.0 8.0 10.0 3 10 0 0 0 0 0]\n",
            " FOUND ['Pinball Dreams' 4.0 10.0 7.0 9 0 0 10 0 0 0]\n",
            " FOUND ['Ring of Fire' 8.0 10.0 2.0 1 0 0 0 10 0 0]\n",
            " FOUND ['Diamond Dome' 3.0 8.0 9.0 6 0 10 0 0 0 0]\n",
            " FOUND ['Open Business' 6.0 10.0 1.0 4 0 0 0 10 0 0]\n",
            " FOUND ['Acute Angle' 5.0 10.0 3.0 7 10 0 0 0 0 0]\n",
            " FOUND ['Double Locking' 3.0 10.0 6.0 8 0 10 0 0 0 0]\n",
            " FOUND ['Twilight Passage' 6.0 10.0 8.0 7 0 0 0 0 10 0]\n",
            " FOUND ['Spider Crawler' 5.0 10.0 6.0 4 0 0 10 0 0 0]\n",
            " FOUND ['Beach Ball' 4.0 10.0 4.0 7 0 0 10 0 0 0]\n",
            " FOUND ['Dueling Beetles' 4.0 4.0 1.0 7 0 0 0 10 0 0]\n",
            " FOUND ['Deep End' 10.0 10.0 1.0 0 0 0 0 0 10 0]\n",
            " FOUND ['Offside Trap' 7.0 10.0 8.0 5 0 0 10 0 0 0]\n",
            " FOUND ['Retina' 1.0 10.0 10.0 7 0 0 10 0 0 0]\n",
            " FOUND ['Last Stop' 7.5 10.0 7.5 3 10 0 0 0 0 0]\n",
            " FOUND [\"Slayer's Paradise\" 9.0 10.0 1.0 1 0 0 0 0 0 10]\n",
            " FOUND ['Center Stage' 2.0 10.0 10.0 7 0 0 10 0 0 0]\n",
            " FOUND ['Island Hopping' 6.5 2.0 4.0 1 0 0 0 0 10 0]\n",
            " FOUND ['Local Businesses' 5.5 10.0 3.0 1 0 0 0 10 0 0]\n",
            " FOUND ['Reflections' 1.0 2.0 4.0 8 0 0 0 10 0 0]\n",
            " FOUND ['Minecart Madness' 7.0 4.5 1.0 5 10 0 0 0 0 0]\n",
            " FOUND ['Hot Potato' 2.0 8.0 8.0 8 0 10 0 0 0 0]\n",
            " FOUND ['Sunny Soccer' 1.0 10.0 4.0 10 0 0 10 0 0 0]\n",
            " FOUND ['Sneaky Sneak' 3.0 10.0 6.5 7 10 0 0 0 0 0]\n",
            " FOUND [\"Goalkeeper's Dream\" 9.0 10.0 1.0 0 0 0 10 0 0 0]\n",
            " FOUND ['Hard Rock Mine' 6.0 2.0 7.5 2 10 0 0 0 0 0]\n",
            " FOUND ['Parallel Plays' 4.0 2.0 0.0 10 0 0 0 10 0 0]\n",
            " FOUND ['Open Space' 8.0 10.0 2.5 2 10 0 0 0 0 0]\n",
            " FOUND ['Hard Lane' 5.0 0.0 7.0 10 0 0 0 0 10 0]\n",
            " FOUND ['Between the Rivers' 4.0 10.0 2.0 7 0 0 0 0 10 0]\n",
            " FOUND ['Coconut Cove' 4.5 10.0 8.5 7 0 0 0 0 0 10]\n",
            " FOUND ['Spice Production' 5.0 8.0 7.0 5 0 0 0 0 10 0]\n",
            " FOUND ['Penalty Kick' 1.0 10.0 1.0 10 0 0 10 0 0 0]\n",
            " FOUND ['Deathcap Trap' 5.0 10.0 2.0 6 10 0 0 0 0 0]\n",
            " FOUND ['Dragon Jaws' 2.0 10.0 6.0 6 0 0 0 0 10 0]\n",
            " FOUND ['Out in the Open' 7.5 4.0 5.0 1 0 0 0 0 10 0]\n",
            " FOUND ['Ahead of the Curve' 4.0 10.0 7.0 6 10 0 0 0 0 0]\n",
            " FOUND ['Safe Zone' 7.5 6.0 1.0 3 0 10 0 0 0 0]\n",
            " FOUND ['Backyard Bowl' 7.0 10.0 1.0 3 0 0 10 0 0 0]\n",
            " FOUND ['G.G. Mortuary' 4.0 8.0 6.0 8 0 10 0 0 0 0]\n",
            " FOUND ['Undermine' 4.0 10.0 8.5 1 10 0 0 0 0 0]\n",
            " FOUND ['Kaboom Canyon' 7.5 10.0 7.0 0 0 10 0 0 0 0]\n",
            " FOUND ['Super Beach' 2.0 9.0 7.0 10 0 0 10 0 0 0]\n",
            " FOUND ['Gem Fort' 4.0 4.0 8.5 1 10 0 0 0 0 0]\n",
            " FOUND ['New Horizons' 7.0 10.0 1.0 3 0 0 0 0 10 0]\n",
            " FOUND ['Four Levels' 6.5 10.0 10.0 6 0 0 0 0 10 0]\n",
            " FOUND ['Rustic Arcade' 8.5 0.0 1.0 0 10 0 0 0 0 0]\n",
            " FOUND [\"Belle's Rock\" 6.0 5.0 0.0 7 0 0 0 0 10 0]\n",
            " FOUND ['Canal Grande' 4.0 2.0 10.0 8 0 0 0 0 7 7]\n",
            " FOUND ['Hideout' 8.0 10.0 0.0 6 0 0 0 0 7 7]\n",
            " FOUND ['Shooting Star' 8.0 0.0 2.0 5 0 0 0 0 7 7]\n",
            " FOUND ['Bear Trap' 4.0 2.0 9.0 6 10 0 0 0 0 0]\n",
            " FOUND ['Encirclement' 4.0 10.0 4.0 5 0 0 10 0 0 0]\n",
            " FOUND ['Misty Meadows' 3.0 7.0 0.0 10 0 0 0 10 0 0]\n",
            " FOUND ['Close Quarters' 2.0 10.0 8.0 8 0 0 0 0 10 0]\n",
            " FOUND ['Back Pocket' 4.0 10.0 1.0 5 0 0 10 0 0 0]\n",
            " FOUND ['Snake Prairie' 0.0 10.0 10.0 0 0 0 0 0 7 7]\n",
            " FOUND ['Sunset Spar' 5.0 10.0 5.0 2 0 0 0 0 10 0]\n",
            " FOUND ['The Great Open' 8.0 10.0 6.0 6 0 0 0 0 0 10]\n",
            " FOUND ['Secret or Mystery' 2.0 7.0 8.0 9 0 10 0 0 0 0]\n",
            " FOUND ['Bridge Too Far' 9.0 5.0 0.0 0 0 10 0 0 0 0]\n",
            " FOUND ['Triple Dribble' 2.0 10.0 7.0 8 0 0 10 0 0 0]\n",
            "Traits per map: 10\n",
            "Embedding(53, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 - Identify if any maps don't have pretrained embeddings\n",
        "for map in maps:\n",
        "  is_in_array = False\n",
        "  for other_map in map_data_list:\n",
        "    if map == other_map[0]:\n",
        "      is_in_array = True\n",
        "      break\n",
        "  if not is_in_array:\n",
        "    print(map)"
      ],
      "metadata": {
        "id": "VVr4SlRkeQCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SECTION 3</h1>\n",
        "<h2>Define & Initialize the model</h2>"
      ],
      "metadata": {
        "id": "bfJfggj7GC2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.0 - Define the model\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, brawler_emb_dim, initial_brawler_embedding, map_emb_dim, initial_map_embedding, num_heads, num_layers, dim_feedforward):\n",
        "        super(Model, self).__init__()\n",
        "        self.brawler_embedding = initial_brawler_embedding\n",
        "        self.map_embedding = initial_map_embedding\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model = brawler_emb_dim + map_emb_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            batch_first=True  # Set batch_first to True\n",
        "        )\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.fc = nn.Linear((brawler_emb_dim + map_emb_dim) * 6, 1)  # Assuming 3 characters per match\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        brawlers, map = torch.split(x, [6, 1], dim=1)\n",
        "        brawler_embedding = self.brawler_embedding(brawlers)\n",
        "\n",
        "        # Add the map on top of each brawler embedding. Thus, each brawler has their own 'impression' of the map.\n",
        "        map_embedding = self.map_embedding(map).repeat(1, 6, 1)\n",
        "\n",
        "        embeddings = torch.cat([map_embedding, brawler_embedding], dim=2)\n",
        "\n",
        "        transformer_output = self.transformer_encoder(embeddings)\n",
        "\n",
        "        # Flatten the output into a 1D array\n",
        "        flattened_output = transformer_output.reshape(transformer_output.size(0), -1)\n",
        "\n",
        "        # Pass the flattened output through a fully connected layer\n",
        "        output = self.fc(flattened_output)\n",
        "\n",
        "        return self.sigmoid(output)"
      ],
      "metadata": {
        "id": "SfTUpMnAyppV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmeaiF_C7IKK"
      },
      "outputs": [],
      "source": [
        "# 3.1 - Hyperparameters\n",
        "\n",
        "brawler_vocab_size = num_brawlers\n",
        "map_vocab_size = num_maps\n",
        "\n",
        "brawler_emb_dim = traits_per_brawler\n",
        "map_emb_dim = traits_per_map\n",
        "\n",
        "# we can manually run more later\n",
        "num_epochs = 1\n",
        "\n",
        "num_heads = 2\n",
        "num_layers = 2\n",
        "dim_feedforward = 64  # Dimension of the last feedforward network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTYm-jhTCPxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e9b471-4cc8-4321-f115-faae5d261a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8365]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 3.2 - Test that the model works\n",
        "\n",
        "model = Model(brawler_emb_dim, initial_brawler_embedding, map_emb_dim, initial_map_embedding, num_heads, num_layers, dim_feedforward)\n",
        "test_input = torch.tensor([[0,2,3,81,5,6,7]])\n",
        "output = model(test_input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOAM6j-RohbK"
      },
      "outputs": [],
      "source": [
        "# 3.3 - Initialize the model, loss function and optimizer\n",
        "\n",
        "torch.manual_seed(41)\n",
        "\n",
        "# Model initialization\n",
        "model = Model(brawler_emb_dim, initial_brawler_embedding, map_emb_dim, initial_map_embedding, num_heads, num_layers, dim_feedforward)\n",
        "\n",
        "# Binary Cross-Entropy loss for binary classification - what we're doing is predicting who wins\n",
        "criterion = nn.BCELoss(reduction='none')\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "  {'params': model.brawler_embedding.parameters(), 'lr': 0.0001},\n",
        "  {'params': model.map_embedding.parameters(), 'lr': 0.0001},\n",
        "  {'params': model.transformer_encoder.parameters(), 'lr': 0.001},\n",
        "  {'params': model.fc.parameters(), 'lr': 0.0002},\n",
        "  {'params': model.sigmoid.parameters(), 'lr': 0.0001},\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SECTION 4</h1>\n",
        "<h2>Testing the Model</h2>\n"
      ],
      "metadata": {
        "id": "3fJtl7HnHgvH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWFSFz_L0NKV"
      },
      "outputs": [],
      "source": [
        "# 4.1 - Initialize\n",
        "\n",
        "current_epoch = 0\n",
        "try:\n",
        "    current_epoch = checkpoint['epoch']\n",
        "except NameError:\n",
        "    current_epoch = 0\n",
        "except KeyError:\n",
        "    current_epoch = 0\n",
        "\n",
        "epoch_losses = []\n",
        "\n",
        "full_dataset_predictions_per_epoch = [] # on all matches\n",
        "partial_dataset_predictions_per_epoch = [] # on matches with a weight greater than 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu3gRugS2aGM",
        "outputId": "00838462-5f72-4e6a-e57f-00f79aa4f675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current epoch: 0\n",
            "Will run 1 epochs\n",
            "Stopping at epoch 1\n"
          ]
        }
      ],
      "source": [
        "# 4.2 - To run more epochs on the model, run this box and everything below it\n",
        "\n",
        "epoch_to_end_on = current_epoch + num_epochs\n",
        "print(f'Current epoch: {current_epoch}')\n",
        "print(f'Will run {num_epochs} epochs')\n",
        "print(f'Stopping at epoch {epoch_to_end_on}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 - Training loop\n",
        "model.train()\n",
        "while current_epoch < epoch_to_end_on:\n",
        "    epoch_loss = 0\n",
        "    current_epoch += 1\n",
        "\n",
        "    i = 0\n",
        "    for batch in train_dataloader:\n",
        "        inputs, targets, weights = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(inputs)\n",
        "        targets = targets.unsqueeze(1)\n",
        "        loss = criterion(pred, targets)\n",
        "        weighted_loss = (loss * weights).mean()\n",
        "        weighted_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += weighted_loss.item()\n",
        "        #if (i % 25 == 0):\n",
        "        #    print(f'Batch {i} loss: {weighted_loss.item()}')\n",
        "        i += 1\n",
        "\n",
        "    print(f'Epoch {current_epoch}: Loss = {weighted_loss}')\n",
        "    epoch_losses.append(weighted_loss)"
      ],
      "metadata": {
        "id": "2XBjXGb9C3EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45880888-f342-4e4b-f774-9a9c070bb911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 0.664782702922821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.4 - Show gradients\n",
        "#for name, param in model.named_parameters():\n",
        "#    if param.grad is not None:\n",
        "#        print(f'Gradient for {name}: {param.grad.norm()}')"
      ],
      "metadata": {
        "id": "G9dwDQxxwiKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvefAyiY5Nis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bc7d09-a4a4-4add-aea3-c0e1c1c15ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 0.664782702922821\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(epoch_losses)):\n",
        "  print(f'Epoch {i}: Loss = {epoch_losses[i]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SECTION 5</h1>\n",
        "<h2>Evaluating the Model</h2>"
      ],
      "metadata": {
        "id": "GbpUiaCHI8LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.0 - Evaluate the model\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "predictions, true_labels, weight_labels = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, targets, weights = batch\n",
        "        outputs = model(inputs).squeeze()\n",
        "        targets = targets.squeeze()\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        weighted_loss = loss * weights\n",
        "        test_loss += weighted_loss.mean().item()\n",
        "\n",
        "        # Collect predictions and true labels for display\n",
        "        predictions.extend(outputs.cpu().numpy())\n",
        "        true_labels.extend(targets.cpu().numpy())\n",
        "        weight_labels.extend(weights.cpu().numpy())\n",
        "\n",
        "# Display a few predictions and their corresponding true labels\n",
        "\n",
        "num_right, total, f_num_right, f_total = 0, 0, 0, 0\n",
        "\n",
        "for predicted_val, target_val, weight in zip(predictions, true_labels, weight_labels):\n",
        "    correct = (predicted_val > 0.5) == (target_val == 1.0)\n",
        "    f_total += 1\n",
        "    if correct:\n",
        "      f_num_right += 1\n",
        "    if weight > 1:\n",
        "      total += 1\n",
        "      if correct:\n",
        "        num_right += 1\n",
        "\n",
        "\n",
        "full_dataset_predictions_per_epoch.append(f_num_right / f_total)\n",
        "\n",
        "partial_dataset_predictions_per_epoch.append(num_right / total)\n",
        "\n",
        "print('Prediction success rate on full training dataset')\n",
        "for prediction in full_dataset_predictions_per_epoch:\n",
        "  print(round(prediction, 3))\n",
        "\n",
        "print('Prediction success rate on training dataset where the winning team has lower trophies')\n",
        "for prediction in partial_dataset_predictions_per_epoch:\n",
        "  print(round(prediction, 3))\n",
        "\n",
        "print()\n",
        "print('Example predictions')\n",
        "for i in range(10):\n",
        "    print(f'pred: {predictions[i]:.2f}, target: {true_labels[i]}')"
      ],
      "metadata": {
        "id": "f2-rJCcEsqT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ddf255-c8f1-4072-c97c-93259011ab75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction success rate on full training dataset\n",
            "0.576\n",
            "Prediction success rate on training dataset where the winning team has lower trophies\n",
            "0.595\n",
            "\n",
            "Example predictions\n",
            "pred: 0.53, target: 1.0\n",
            "pred: 0.51, target: 1.0\n",
            "pred: 0.56, target: 1.0\n",
            "pred: 0.55, target: 0.0\n",
            "pred: 0.59, target: 0.0\n",
            "pred: 0.62, target: 0.0\n",
            "pred: 0.51, target: 0.0\n",
            "pred: 0.56, target: 0.0\n",
            "pred: 0.41, target: 0.0\n",
            "pred: 0.51, target: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrApxs1ZEXc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a28518d-bff0-43f3-a266-d80846363d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triple Dribble - Frank 5x:\n",
            "MOE - WILLOW - BEA - empty1 - empty2 - BERRY - MR. P - RUFFS - BONNIE - GUS - \n",
            "\n",
            "Double Swoosh: SANDY LEON POCO:\n",
            "MOE - DARRYL - WILLOW - DRACO - MELODIE - BEA - MR. P - empty1 - RUFFS - ASH - \n",
            "\n",
            "Hot Potato: BIBI CHUCK BULL:\n",
            "MOE - DARRYL - DRACO - ASH - SAM - WILLOW - OTIS - BUSTER - CHESTER - HANK - \n",
            "\n",
            "Hot Potato: BIBI COLT DYNAMIKE\n",
            "MOE - DARRYL - ASH - SAM - LILY - BUSTER - HANK - CORDELIUS - DOUG - BULL - \n",
            "\n",
            "Hot Potato: MELODIE COLT DYNAMIKE\n",
            "MOE - DARRYL - WILLOW - LILY - ASH - EDGAR - SAM - BUSTER - CORDELIUS - CHUCK - \n",
            "\n",
            "Deep End: NANI COLT EVE\n",
            "MOE - DARRYL - BONNIE - DRACO - LILY - ASH - GUS - R-T - HANK - KIT - \n",
            "\n",
            "Hot Zone: JACKY BULL HANK:\n",
            "MOE - DARRYL - BEA - BONNIE - CHUCK - LOLA - OTIS - 8-BIT - empty1 - ASH - "
          ]
        }
      ],
      "source": [
        "# 5.1 - Example final brawler recommendation\n",
        "\n",
        "def recommend_brawler(battle):\n",
        "    model.eval()\n",
        "    guesses = []\n",
        "    # Convert match elements to indices\n",
        "    for i in range(6):\n",
        "        try:\n",
        "          battle[i] = brawler_index(battle[i])\n",
        "        except ValueError:\n",
        "          continue\n",
        "\n",
        "    try:\n",
        "      battle[6] = map_index(battle[6])\n",
        "    except ValueError:\n",
        "      print(f'Did not find {battle[6]} in list')\n",
        "      return\n",
        "\n",
        "    guesses = []\n",
        "\n",
        "    for i in range(len(brawlers)):\n",
        "        battle[5] = i  # Set the current brawler index in match\n",
        "\n",
        "        input_tensor = torch.tensor(battle, dtype=torch.long).unsqueeze(0)\n",
        "        output = model(input_tensor).squeeze()\n",
        "\n",
        "        output_value = round(float(output.item()), 2)\n",
        "\n",
        "        guess = {\n",
        "            'id': int(i),\n",
        "            'val': output_value\n",
        "        }\n",
        "        guesses.append(guess)\n",
        "\n",
        "\n",
        "    guesses = sorted(guesses, key=lambda x: x['val'], reverse=False)\n",
        "    for guess in guesses[:10]:\n",
        "        print(f'{brawlers[guess[\"id\"]]} -', end=' ')\n",
        "\n",
        "\n",
        "\n",
        "print('Triple Dribble - Frank 5x:')\n",
        "recommend_brawler(['FRANK', 'FRANK', 'FRANK', 'FRANK', 'FRANK', '?', 'Triple Dribble']) # should recommend a tank buster\n",
        "\n",
        "print('\\n\\nDouble Swoosh: SANDY LEON POCO:')\n",
        "recommend_brawler(['SANDY', 'LEON', 'POCO', 'SPIKE', 'JESSIE', '?', \"Double Swoosh\"])  # should recommend crow, maybe gene\n",
        "\n",
        "print('\\n\\nHot Potato: BIBI CHUCK BULL:')\n",
        "recommend_brawler(['BIBI', 'CHUCK', 'BULL', 'COLT', 'DYNAMIKE', '?', 'Hot Potato'])   # should recommend a good heist brawler;\n",
        "\n",
        "print('\\n\\nHot Potato: BIBI COLT DYNAMIKE')\n",
        "recommend_brawler(['BIBI', 'COLT', 'DYNAMIKE', 'BARLEY', 'EDGAR', '?', 'Hot Potato'])   # should recommend a good heist brawler;\n",
        "\n",
        "print('\\n\\nHot Potato: MELODIE COLT DYNAMIKE')\n",
        "recommend_brawler(['MELODIE', 'COLT', 'DYNAMIKE', 'BULL', 'ROSA', '?', 'Hot Potato'])   # should recommend a good heist brawler;\n",
        "\n",
        "print('\\n\\nDeep End: NANI COLT EVE')\n",
        "recommend_brawler(['NANI', 'COLT', 'EVE', 'BROCK', '8-BIT', '?', 'Deep End'])         # sniper\n",
        "\n",
        "print('\\n\\nHot Zone: JACKY BULL HANK:')\n",
        "recommend_brawler(['JACKY', 'BULL', 'HANK', 'BYRON', 'POCO', '?', 'Ring of Fire'])    # resistance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l62ROMXH2OyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3n3jhhXC0Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2226fa-f52a-466f-d86a-8b6d1d7af2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These battles should produce near identical outputs:\n",
            "0.48416\n",
            "0.49152\n",
            "0.50247\n",
            "0.49979\n",
            "0.49361\n",
            "0.48892\n",
            "Mirror matchups, should be close to 0.5:\n",
            "0.51382\n",
            "0.52899\n",
            "0.51501\n",
            "0.52343\n",
            "0.51836\n",
            "0.50256\n",
            "0.50255\n"
          ]
        }
      ],
      "source": [
        "# 5.2 - Test the model's consistency.\n",
        "#       We want a model that is permutation invariant - meaning it should give the same results regardless of how a team is ordered.\n",
        "#       I haven't come up with a solution for this yet.\n",
        "\n",
        "same_battles = [\n",
        "    [0, 1, 2, 3, 4, 5, 6],\n",
        "    [0, 2, 1, 3, 5, 4, 6],\n",
        "    [1, 2, 0, 4, 5, 3, 6],\n",
        "    [1, 0, 2, 4, 3, 5, 6],\n",
        "    [2, 0, 1, 5, 3, 4, 6],\n",
        "    [2, 1, 0, 5, 4, 3, 6]\n",
        "]\n",
        "\n",
        "print('These battles should produce near identical outputs:')\n",
        "for battle in same_battles:\n",
        "  input = torch.tensor(battle).unsqueeze(0)\n",
        "  output = model(input)\n",
        "  print(round(output.squeeze().item(), 5))\n",
        "\n",
        "mirror_matchups = [\n",
        "    [0, 0, 0, 0, 0, 0, 6],\n",
        "    [1, 1, 1, 1, 1, 1, 6],\n",
        "    [2, 2, 2, 2, 2, 2, 6],\n",
        "    [3, 3, 3, 3, 3, 3, 6],\n",
        "    [4, 4, 4, 4, 4, 4, 6],\n",
        "    [5, 5, 5, 5, 5, 5, 6],\n",
        "    [6, 6, 6, 6, 6, 6, 6]\n",
        "]\n",
        "\n",
        "print('Mirror matchups, should be close to 0.5:')\n",
        "for battle in mirror_matchups:\n",
        "  input = torch.tensor(battle).unsqueeze(0)\n",
        "  output = model(input)\n",
        "  print(round(output.squeeze().item(), 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>SECTION 6</h1>\n",
        "<h2>Saving the Model</h2>"
      ],
      "metadata": {
        "id": "9sdkOIV8PcqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvLjl7_goEPg"
      },
      "outputs": [],
      "source": [
        "# 6.1 - Save the model for inference\n",
        "#torch.save(model.state_dict(), 'bm_7_4_611-612_withgaps.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpMaHNUqD58D"
      },
      "outputs": [],
      "source": [
        "# 6.2 - Saving the model for training\n",
        "#torch.save({\n",
        "#    'epoch': current_epoch,\n",
        "#    'model_state_dict': model.state_dict(),\n",
        "#    'optimizer_state_dict': optimizer.state_dict(),\n",
        "#    'loss': epoch_losses[-1],  # Save the final epoch's average loss\n",
        "#}, 'brawl_mind_6_25.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.3 - Identify if any maps don't have pretrained embeddings before savin\n",
        "for map in maps:\n",
        "  is_in_array = False\n",
        "  for other_map in map_data_list:\n",
        "    if map == other_map[0]:\n",
        "      is_in_array = True\n",
        "      break\n",
        "  if not is_in_array:\n",
        "    print(map)"
      ],
      "metadata": {
        "id": "-1pkqmYeeFyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.4\n",
        "# ! IMPORTANT !\n",
        "# Add this into the backend's env file\n",
        "# We need to know the order the maps are in\n",
        "print('Paste this into backend/app/config.py')\n",
        "print('maps = [')\n",
        "\n",
        "for map in maps:\n",
        "  print('\"' + map + '\",', end=' ')\n",
        "\n",
        "print('\\n]')\n",
        "\n",
        "\n",
        "# Currently, the model has no training data on these maps, but we can initialize them manually the same way we do with all the other maps.\n",
        "# Just means that the model can't adjust them.\n",
        "print(' \"Canal Grande\", \"Hideout\", \"Shooting Star\",')"
      ],
      "metadata": {
        "id": "4pEyIP7ldRze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2f11f3-2a05-4651-a0c5-e80dff5b677a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Gem Fort\", \"Flaring Phoenix\", \"Last Stop\", \"Island Hopping\", \"Diamond Dome\", \"Deep End\", \"Penalty Kick\", \"Bear Trap\", \"Between the Rivers\", \"Hard Lane\", \"Local Businesses\", \"Twilight Passage\", \"Pinball Dreams\", \"Snake Prairie\", \"Close Quarters\", \"Kaboom Canyon\", \"Hard Rock Mine\", \"Parallel Plays\", \"Goldarm Gulch\", \"Shooting Star\", \"Backyard Bowl\", \"Open Business\", \"Double Swoosh\", \"Sunny Soccer\", \"Minecart Madness\", \"Dueling Beetles\", \"Offside Trap\", \"Sneaky Fields\", \"Sunset Spar\", \"Out in the Open\", \"Misty Meadows\", \"Super Beach\", \"Beach Ball\", \"Open Space\", \"Center Stage\", \"Secret or Mystery\", \"Hot Potato\", \"Bridge Too Far\", \"New Horizons\", \"Safe Zone\", \"Ahead of the Curve\", \"Four Levels\", \"Belle's Rock\", \"Triple Dribble\", \"Retina\", \"Ring of Fire\", \"Sneaky Sneak\", \"Rustic Arcade\", \"The Great Open\", \"Encirclement\", \"Undermine\", \"Acute Angle\", \"Back Pocket\",  \"Canal Grande\", \"Hideout\", \"Shooting Star\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.5 - Save the embeddings to CSV format so they can be manually modified by the user.\n",
        "brawler_embedding_array = model.brawler_embedding.weight.detach().numpy()\n",
        "\n",
        "brawler_embeddings_df = pd.DataFrame(brawler_embedding_array)\n",
        "\n",
        "brawler_embedddings_df.drop(columns=['brawler'], axis=1, inplace=True)\n",
        "\n",
        "brawler_embeddings_df.to_csv('brawler_embeddings.csv', index=False)"
      ],
      "metadata": {
        "id": "3H4U_rLjVyGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.6 - Save the maps to csv.\n",
        "map_embedding_array = model.map_embedding.weight.detach().numpy()\n",
        "\n",
        "map_embeddings_df = pd.DataFrame(map_embedding_array)\n",
        "\n",
        "map_embedddings_df.drop(columns=['map'], axis=1, inplace=True)\n",
        "\n",
        "map_embeddings_df.to_csv('map_embeddings.csv', index=False)"
      ],
      "metadata": {
        "id": "hDEprHCjWiYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.7 - Save the model\n",
        "#torch.save(model.state_dict(), 'draftstars.pt')"
      ],
      "metadata": {
        "id": "wIpyIpS6pn6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.6 - Download\n",
        "#from google.colab import files\n",
        "#files.download('draftstars.pt')\n",
        "#files.download('map_embeddings.csv')\n",
        "#files.download('brawler_embeddings.csv')"
      ],
      "metadata": {
        "id": "FIY0ihgdpp6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>BEFORE EXITING</h2>\n",
        "\n",
        "*   Make sure to copy and paste the list of maps in cell 6.4.\n",
        "*   Paste it into to 'maps' variable in backend/app/config.py.\n",
        "\n"
      ],
      "metadata": {
        "id": "wo8S7HWZXGOL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}